# TODO: Train a LightGBM model and benchmark against RandomForest.
#       Refactor shared prep/eval into utils to avoid duplication.
#       Compare via PR-AUC + Recall@Precisionâ‰¥95% and save the better as models/fraud_best.pkl.
